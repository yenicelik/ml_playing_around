{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|']\n",
      "Vocab size 82\n",
      "Entire data size 199442\n",
      "Number of batches 48\n",
      "\n",
      "Iterations through data 48\n",
      "\n",
      "Number of batches saved in X_batches: 48\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  1\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  2\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  3\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  4\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  5\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  6\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  7\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  8\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  9\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "(4096,) (4096,)\n",
      "Epochs through:  10\n",
      "(4096,) (4096,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "\"\"\" Future ideas:\n",
    "    * Create Variable Batch Sizes: Transition between batches are then included in modeling the language... any possible good?\n",
    "\"\"\"\n",
    "\n",
    "class TextLoader():\n",
    "    \"\"\" Helper function to load in (batches of) text \"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size, seq_length, input_file):\n",
    "        \"\"\" Load data to generate text from. Set batch pointer to zero.\"\"\"\n",
    "        self.ip = 0 #'insruction' pointer\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.input_file = input_file\n",
    "        \n",
    "        with open(self.input_file, 'r') as text_source:\n",
    "            #self.text = text = np.loadtxt(text_source)\n",
    "            #print self.text\n",
    "            self.text = text_source.readlines()[0]\n",
    "            #print(text)\n",
    "            #must open up file..\n",
    "            \n",
    "            self.chars = list(set(self.text))\n",
    "            print(sorted(self.chars))\n",
    "            \n",
    "            self.vocab_size = len(self.chars)\n",
    "            print(\"Vocab size %d\" % self.vocab_size)\n",
    "            \n",
    "            self.data_size = len(self.text)\n",
    "            print(\"Entire data size %d\" % self.data_size)\n",
    "                \n",
    "        self.map_char2num = { ch:i for i,ch in enumerate(self.chars) }\n",
    "        self.map_num2char = { i:ch for i,ch in enumerate(self.chars) }\n",
    "        \n",
    "        self.num_batches = self.data_size / (self.batch_size * self.seq_length)\n",
    "        print(\"Number of batches %d\" % self.num_batches)\n",
    "        self.epochs_through = 0\n",
    "        \n",
    "        self.create_batches()\n",
    "        \n",
    "    def create_batches(self):\n",
    "        \"\"\" Creates a number of batches, saved in self.x_batches and self.y_batches\"\"\"\n",
    "        \n",
    "        if (self.num_batches == 0):\n",
    "            assert False, \"Not enough data to receive batch! :: In function next_batch_pointer of class TextLoader()\"\n",
    "        \n",
    "        processed_text = self.char2num(self.text)   #turn into numbers \n",
    "        processed_text = processed_text[:self.num_batches * self.batch_size * self.seq_length]\n",
    "        \n",
    "        x = processed_text\n",
    "        y = np.zeros(x.shape)\n",
    "        y[:-1] = np.copy(x[1:])\n",
    "        y[-1] = np.copy(x[0])\n",
    "        \n",
    "        self.X_batches = np.split(x, self.num_batches)\n",
    "        self.y_batches = np.split(y, self.num_batches)     \n",
    "        \n",
    "        \n",
    "    #################\n",
    "    #Helper functions\n",
    "    def char2num(self, char_arr):\n",
    "        out = np.zeros(len(char_arr), dtype=np.int32)  #will be changed to one-hot anyways... #dtype=float32 if worked on this\n",
    "        for i in range(out.shape[0]):\n",
    "            out[i] = self.map_char2num[ char_arr[i] ]\n",
    "        return out\n",
    "    \n",
    "    def num2char(self, num_arr):\n",
    "        out = \"\"\n",
    "        for i in range(num_arr.shape[0]):\n",
    "            out += self.map_char2num[ num_arr[i] ]\n",
    "        #out = np.zeros(len(char_arr), dtype=np.int32)  #will be changed to one-hot anyways... #dtype=float32 if worked on this\n",
    "        return out\n",
    "    #Helper functions\n",
    "    #################\n",
    "    \n",
    "    \n",
    "    def get_next_batch(self):\n",
    "        \"\"\" Get next batch of data. This should be a multiple of a sequence \n",
    "        length, and a multiple of the batch size \"\"\"\n",
    "        x, y = self.X_batches[self.ip], self.y_batches[self.ip]\n",
    "        self.ip += 1\n",
    "        if self.ip == self.num_batches:\n",
    "            self.epochs_through += 1\n",
    "            print \"Epochs through: \", self.epochs_through\n",
    "            self.reset_batch_pointer()\n",
    "            \n",
    "        return x, y\n",
    "           \n",
    "    def reset_batch_pointer(self):\n",
    "        self.ip = 0\n",
    "        return True\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TextLoader = TextLoader(batch_size = 32, \n",
    "                            seq_length = 128, #the longer the better\n",
    "                            input_file = 'data/dailymail_header/input.txt'\n",
    "                           )\n",
    "    \n",
    "    iterations_for_epoch = (TextLoader.data_size) / (TextLoader.batch_size * TextLoader.seq_length) #bcs indexing is from zero...\n",
    "    print\n",
    "    print \"Iterations through data\", iterations_for_epoch\n",
    "    print\n",
    "    \n",
    "    print \"Number of batches saved in X_batches:\", len(TextLoader.X_batches)\n",
    "    \n",
    "    for _ in range(iterations_for_epoch * 10):\n",
    "        x, y = TextLoader.get_next_batch()\n",
    "        print x.shape, y.shape\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable lstm/embedding does not exist, disallowed. Did you mean to set reuse=None in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d3995056f1c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m                   \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                   \u001b[0mgrad_clip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                   \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m82\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                  )\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d3995056f1c4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, seq_length, lstm_size, num_layers, grad_clip, vocab_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0msoftmax_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax_b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;31m#some further processing needed?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections)\u001b[0m\n\u001b[1;32m    337\u001b[0m       \u001b[0m_get_default_variable_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m       \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m       collections=collections)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device)\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0mfull_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m           \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m           collections=collections, caching_device=caching_device)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m       raise ValueError(\"Variable %s does not exist, disallowed.\"\n\u001b[0;32m--> 135\u001b[0;31m                        \" Did you mean to set reuse=None in VarScope?\" % name)\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitializing_from_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m       raise ValueError(\"Shape of a new variable (%s) must be fully defined, \"\n",
      "\u001b[0;31mValueError\u001b[0m: Variable lstm/embedding does not exist, disallowed. Did you mean to set reuse=None in VarScope?"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import seq2seq\n",
    "import pip\n",
    "import os\n",
    "\n",
    "from tensorflow.python.ops import rnn\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, batch_size, seq_length, lstm_size, num_layers, grad_clip, vocab_size):\n",
    "        \"\"\" Build the actual model \"\"\"\n",
    "        #Define crucial hyperparameters / parameters\n",
    "        self.lr = tf.Variable(0.0, trainable=False)        \n",
    "        \n",
    "        #Define input and output\n",
    "        self.input_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "        self.output_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "        \n",
    "        #Define the model\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=lstm_size) #can choose if basic or otherwise later on...\n",
    "        self.cell = cell = rnn_cell.MultiRNNCell([cell] * num_layers)\n",
    "        self.initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "        \n",
    "        with tf.variable_scope(\"lstm\", reuse=True):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [lstm_size, vocab_size])\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                embedding = tf.get_variable(\"embedding\", [vocab_size, lstm_size])\n",
    "                inputs = tf.nn.embedding_lookup(embedding, self.input_data)\n",
    "                #some further processing needed?\n",
    "                \n",
    "        \n",
    "        def loop(prev, _):\n",
    "            prev = tf.matmul(prev, softmax_w) + softmax_b\n",
    "            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "            return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "        \n",
    "        outputs, states = seq2seq.rnn_decoder(\n",
    "                                            inputs, \n",
    "                                            self.initial_state, \n",
    "                                            cell, \n",
    "                                            loop_function=loop,\n",
    "                                            scope='lstm')\n",
    "        \n",
    "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        \n",
    "        loss = seq2seq.sequence_loss_by_example(\n",
    "                                                [self.logits],\n",
    "                                                [self.output_data],\n",
    "                                                [tf.ones([batch_size * seq_length])],\n",
    "                                                vocab_size\n",
    "                                                )\n",
    "        self.cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "        self.final_state = last_state\n",
    "        \n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), grad_clip)\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars)) # what happens for one single iteration\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "    Model = Model(batch_size=32, \n",
    "                  seq_length=128, \n",
    "                  lstm_size=512, \n",
    "                  num_layers=2, \n",
    "                  grad_clip=5,\n",
    "                  vocab_size=82\n",
    "                 )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-8-2674f478c680>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-2674f478c680>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    iterations_for_epoch = (TextLoader.data_size) / (TextLoader.batch_size * TextLoader.seq_length) #bcs indexing is from zero...\u001b[0m\n\u001b[0m                                                                                                                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def train(num_epochs, learning_rate, decay_rate, batch_size, seq_length, input_file):\n",
    "\n",
    "\tTextLoader = TextLoader(batch_size = batch_size, \n",
    "                            seq_length = seq_length, #the longer the better\n",
    "                            input_file = input_file\n",
    "                           )\n",
    "    \n",
    "    iterations_for_epoch = (TextLoader.data_size) / (TextLoader.batch_size * TextLoader.seq_length) #bcs indexing is from zero...\n",
    "    \n",
    "\n",
    "\tmodel = Model(batch_size=32, \n",
    "                  seq_length=128, \n",
    "                  lstm_size=512, \n",
    "                  num_layers=2, \n",
    "                  grad_clip=5,\n",
    "                  vocab_size=TextLoader.vocab_size\n",
    "                 )\n",
    "\n",
    "\twith tf.Sess() as sess:\n",
    "\t\ttf.initialize_all_variables().run()\n",
    "\n",
    "\t\t#check again what substitutes one epoch...\n",
    "\t\tfor e in range(num_epochs):\n",
    "\t\t\ttf.assign(model.lr, learning_rate * (decay_rate ** e))\n",
    "\t\t\tTextLoader.reset_batch_pointer()\n",
    "            state = sess.run(model.initial_state) #why initial_state?...\n",
    "\n",
    "            for b in range(TextLoader.num_batches):\n",
    "                start = time.time()\n",
    "                x, y = TextLoader.get_next_batch()\n",
    "                feed = {\n",
    "                \t\tmodel.input_data: x, \n",
    "                \t\tmodel.output_data: y, \n",
    "                \t\tmodel.initial_state: state\n",
    "                \t\t}\n",
    "                train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "                end = time.time()\n",
    "                print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\" \\\n",
    "                    .format(e * TextLoader.num_batches + b,\n",
    "                            num_epochs * TextLoader.num_batches,\n",
    "                            e, train_loss, end - start))\n",
    "                \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\ttrain(\n",
    "\t\tnum_epochs = 5, \n",
    "\t\tlearning_rate = 1e-2, \n",
    "\t\tdecay_rate = 0.8, \n",
    "\t\tbatch_size = 32, \n",
    "\t\tseq_length = 128, \n",
    "\t\tinput_file = 'data/dailymail_header/input.txt'\n",
    "\t\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
